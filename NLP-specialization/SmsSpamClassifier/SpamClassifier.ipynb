{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Importing libs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "import pandas as pd\r\n",
    "import re\r\n",
    "import nltk\r\n",
    "nltk.download(\"stopwords\")\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.stem.porter import PorterStemmer\r\n",
    "ps = PorterStemmer()\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Syed Arsalan\n",
      "[nltk_data]     Amin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading data\r\n",
    "### UCI Machine Learning Repository:\r\n",
    "### [Download SMS Spam Collection Data Set](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "corpus = []\r\n",
    "messages = pd.read_csv(\"E:\\\\DataScience & AI\\\\Github_repo\\\\NLP-specialization\\\\SmsSpamClassifier\\\\SMSSpamCollection\",\r\n",
    " sep=\"\\t\", names=[\"label\", \"message\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Pre-processing | Stemming\r\n",
    "## - You can also use Lemmatization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "for i in range(0, len(messages)):\r\n",
    "    review = re.sub('[^a-zA-Z]', ' ', messages['message'][i])\r\n",
    "    review = review.lower()\r\n",
    "    review = review.split()\r\n",
    "    review = [ps.stem(word) for word in review if word not in set(stopwords.words(\"english\"))]\r\n",
    "    review = ' '.join(review)\r\n",
    "    corpus.append(review)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating BAG OF WORDS Model\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "cv = CountVectorizer(max_features=5000) # BAG OF WORDS\r\n",
    "X = cv.fit_transform(corpus)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "y = pd.get_dummies(messages['label']) # converting 'ham' and 'spam' to 0-1 format.\r\n",
    "y = y.iloc[:, 0].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training and Prediction - Naive Bayes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "model = MultinomialNB()\r\n",
    "spam_detection_model = model.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "y_pred = spam_detection_model.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 209,   12],\n",
       "       [  11, 1440]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\r\n",
    "accuracy"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.986244019138756"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('tf2.3': conda)"
  },
  "interpreter": {
   "hash": "ecb34a50eebf59cac06ac1dcb36edf9923f0a9d91d6df6a9f6859de73be3b1af"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}